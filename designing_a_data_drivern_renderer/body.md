# Designing a Data-Driven Renderer

## 9.1 Introduction
ハードウェアアクセラレーションが登場して以来、3Dグラフィックスのレンダリングは、ほとんど一握りのAPIを使用して達成されてきました。そのため、リアルタイム3Dビジュアルを特徴とするほぼすべてのエンジンは、これらのうちの1つ以上を使用することが一般的に受け入れられています。実際、コンピューティングの複雑さとパワーが増すにつれ、単一の開発スタジオがハードウェアの能力にアクセスするための独自のコードを作成したり、物理学やAIなどの分野で最新の技術をすべて実装したりすることは考えられなくなってきています。各 API は、特定の問題領域に最適な独自のモデルとパラダイムを使用して構築され、その領域の構造や概念を高次の用語で表現しています。グラフィックスAPIもこの点では同じで、各フレームをレンダリングする際に比較的大量の情報をハードウェアに送信しなければならない仮想デバイスとしてハードウェアを公開しています。このインターフェイスは、ゲームやシミュレーションのコアロジックが実装される環境を形成します。この章では、ほとんどのゲームエンジンのコアにある論理的なシミュレーションと、グラフィック API を通じてフレームをレンダリングするために必要な厳密に順序付けられたコマンドの流れとの間のギャップを埋めるレンダラーの設計を検討します。これは、シミュレートされたシーンを視覚化するために使用されるプログラムによって解決される問題ですが、ここでは、使用されるレンダリングスタイルについて最小限の仮定をして、レンダリングパイプラインを構築するための柔軟なデータ駆動型の基盤を提供することに焦点を当てています。

目的は、レンダリングの設計をエンジン アーキテクチャから切り離すソリューションを提供することです。このようなソリューションにより、個々のプロジェクトのレンダリング技術がその生涯にわたって進化し、コード ベースやアセット パイプラインへの影響を最小限に抑えながら、新しい技術の評価や開発が可能になります。

## 9.2 Problem Analysis
これまでのところ、私たちの目標は、レンダリングスタイルの柔軟性に重点を置いて、私たちのエンジンと一致したグラフィックAPIの機能を公開することだと定義してきました。すでに述べたように、すべてのAPIは独自のモデルに合わせて設計されており、エンジンの使用パターンと多かれ少なかれ一致している必要があります。この範囲とレンダラーモジュールのタスクを決定するには、API と意図されたエンジンのインターフェースの両方を詳細に調査する必要があります。これらの問題についての議論は、コードでの実装の具体的な内容よりも、観察されるより広範なパターンに焦点を当てて、設計または概念的なレベルで行われます。このようにして、問題領域を簡潔に記述することができ、言語や他の実装の詳細に関係なく、グラフィックスAPIとエンジンの可能な限り広い範囲に解決策を適用することができます。

### 9.2.1 Graphics API Model
ほとんどのグラフィックス API は、OpenGLstandards に基づくもの [Shreiner et al. 06] と、Microsoft の Direct3D ファミリーのライブラリ [Microsoft 09] の 2 つのグループのいずれかに属します。実装レベルでは、これら2つのグループの構造は非常に異なっています。OpenGLは、C言語にルーツを持つプロシージャルモデルに基づいて構築されており、Direct3Dは、COM（Component Object Model）プログラミングモデルを使用したオブジェクト指向の構造を持っています。これにもかかわらず、基本的な構造と使用パターンは両グループに共通しています[Sterna 10]（他のすべてのAPIにも共通しています）。この実装レベルを超えて、すべてのグラフィックス API に共通の構造とパターンを使用して、すべてに適用可能な単一のモデルを定義することができます。これらの概念の多くは、ほとんどのグラフィックスプログラマーにとって非常に馴染み深いものでしょう。そのため、この章では、この章の残りの部分の基礎となる考え方のコンセンサスを得ることを目的としています。グラフィックスAPIが何をするのかということには関心がなく、グラフィックスAPIとアプリケーションとの間の相互作用のパターンのみを取り上げます。グラフィックス API は、自己完結型のプロセッサとメモリを搭載した拡張カードや、ネットワーク接続を介してアクセスする完全に独立したコンピュータなど、メインシステムのアーキテクチャから離れたハードウエアの機能をラップするように設計されています。この距離は、仮想デバイスという概念で表現されていますが、正確な用語はAPIによって異なります。これは、デバイスが所有するメモリの割り当てとデアロケートを制御し、通常、ハードウェアデバイスにローカルメモリ、メインシステムとグラフィックスハードウェアの両方から同時にdoingsoを避けるために、メインシステムからこのメモリへの直接アクセスを制御します。2.状態管理 グラフィックスハードウェアの操作は、すべての適切な情報をパラメータとして描画関数に渡すには複雑すぎます。また、描画コマンドの実行はデバイスのコンフィグレーションから切り離されています。このような関数を呼び出してもデバイスのリソースを変更することはなく、その効果は完全に逆になります。3. 実行 現在のデバイス構成に対して、描画または他のコマンド（フレームバッファのクリアなど）を実行します。その結果、デバイスが所有するリソースが永久的に変更される可能性があります。グラフィックデバイスの主な機能は描画コマンドを実行することであり、そのためデバイスの大部分はこのタスクに専念しています。
 デバイスのコアは一連のストリーム処理ユニット(図9.1)として構造化されており、それぞれが頂点情報のストリームをフレームバッファ内のピクセルに変換する際に固有の機能を持っています。


ラスタ、マージ、トライアングルアセンブラなどの固定機能ユニットは、パイプラインのそのステージの間の操作を構成するために使用される特定の状態値のセットを持つことを特徴としています。例えば、ラスタステージは、ラスタライズ中にフェースの巻上げを決定したり、レンダリングのためにフレームバッファのサブセクションをマスクオフしたりする様々なカリング条件をサポートしています。一方、プログラマブルシェーダユニット（図9.2）には、さまざまな一般的なリソースが関連付けられています。各ユニットの性質はパイプライン内での位置によって固定されていますが、正確な機能は、ドローコールが行われたときにユニットにロードされたシェーダプログラムによって定義されます。この柔軟性に対応するため、シェーダユニットに関連付けられたリソースは、他のステージのステート値のように特定の意味に固定されているのではなく、シェーダプログラムとアプリケーションの両方から見えるようになっている汎用のリソースです。これらのリソースには以下のものが含まれます。

+ 入力ストリーム。同じ長さの複数のストリームをシェーダにアタッチすることができ、プログラムは各要素に対して1回実行されます。これらの値は、シングルドロー呼び出 しでシェーダのすべてのイテレーションに渡って変更できる唯一の値です。
+ 出力ストリーム シェーダプログラムの各実行は、1 つ以上の出力ストリームに値を出力します。

+ 定数レジスタ。定数レジスタ 各シェーダユニットには多数の定数レジスタがあり、描画呼び出しの前に設定することができます。テクスチャサンプラー テクスチャサンプラーは、シェーダが多次元配列のデータにアクセスできるようにします。

+ テクスチャサンプラー テクスチャサンプラーは、シェーダがデータの多次元配列にアクセスできるようにします。

このデータは、さまざまなフィルタリングオプションを使用してランダムにインデックス化することができます。シェーダとエンジンの間でリソースの標準化されたマッピングを 提示しなければ、エンジンに、与えられたレジスタ、サンプラー、またはスト リームインデックスにどの値を関連付けるべきかを示す指示はほとんどありません。幸いなことに、HLSL、Cg、GLSL などの高レベルシェーディング言語は、シンプルでエレガントな解決策を提供しています（図 9.3）。これらの言語は、シェーダプログラム内で定義可能な名前付きパラメータとして、これらのリソースを公開しています。各パラメータは型と名前で識別する必要があり、場合によってはオプションでセマンティックを与えることもできます。この情報はエンジンにも公開され、固定関数の状態と同程度の詳細を提供しながら、データ（シェーダコード）で定義できる柔軟性を備えています。このように、標準化された有限のステート値のセットとのインターフェイスから、タイプと名前、またはセマンティックの組み合わせで定義された無制限の値のセットへと重点が移され、エンジン設計に非常に異なる課題が生じます。ハードウェアの世代ごとに新機能が公開され、パイプラインのレイアウトが拡張・変更されています（図 9.4）。Direct3D API の過去 4 世代では、固定機能からプログラマブルなステージへと大幅に移行しています。この傾向は今後も続くと考えられ、どのようなソリューションでもこれを認識しておく必要があります。

+ コマンドバッファ。このデバイスは単にグラフィックスハードウエアにコマンドを送信しているだけなので、コマンドはすぐに実行されるのではなく、コマンドバッファの中でキューに入れられ、グラフィックスハードウエアに送信されて実行されます。コマンドバッファを調べると、フレーム全体での使用パターンがはっきりとわかります（図9.5）。いくつかの状態設定コマンドの後に、描画（またはクリア）コマンドが実行されます。本章では、このパターンをバッチと定義します。バッチとは、デバイス上で実行される単一の実行単位で、パイプラインの設定に必要なすべての状態設定コマンドと、それ自身の描画コマンドを含んでいます。したがって、フレームのレンダリングは、順番に実行される一連のバッチとして記述することができます（図9.6）。

+ まとめると、最近のグラフィックスAPIは、レンダリングに関連した高次の概念を認識していないと言えます。要約すると、最新のグラフィックスAPIは、ライト、キャラクター、スプライト、ポストプロセスなどのレンダリングに関連するような高レベルの概念を認識していないと言えます。その代わりに、様々なハードウェア上で統一された機能のセットを公開する均質化インターフェースを提供することに焦点を当てています。
  + セッションの過程では、レンダリング中に使用可能な状態になるようにデバイスメモリ内のリソースを管理します。
  + フレームの過程で、プログラマブル・ユニットに適切なシェーダを割り当ててバッチを構築し、アプリケーションから固定ファンクション・ステート情報とシェーダ・パラメータの両方を収集します。これらのバッチは、フレームのコマンドバッファを生成するために正しい順序で実行されなければなりません。


### 9.2.2 Engine Model: Intended Pattern of Use
すべてのエンジンは、作者の個人的な要求や好みに応じたデザインモデルに従っているため、グラフィックスAPIとは異なり、すべてのエンジンに適合する一般的なモデルを定義することは非常に困難です。しかし、典型的なゲームやシミュレーション中のレンダリングの一般的な例を抽出し、そこからほとんどのエンジンに存在すると予想されるパターンを導き出すことは可能です。これらのパターンを組み合わせて洗練させることで、すべてのレンダリングの一般的なモデルを導き出すことができます。これらのレンダリングの例は、多くの場合、エンジン内の別々のモジュールの領域と考えられ、それぞれがその領域に最適なレンダリングモデルを使用しています。また、それぞれが独自のスタイルのシステム設計をしている別の作者が担当している場合もあります。API より上のレベルでレンダリング用の単一のインターフェイスを提供することで、これらのシステム間の境界を越えたレンダリング効果を作成したり、まったく新しいシステムを構築したりすることがはるかに簡単になります。

+ 3Dシーンレンダリング。複雑化する3Dシーンの2D画像をレンダリングすることは、長年にわたりグラフィックス開発の原動力となってきました。OpenGLやDirect3DなどのグラフィックスAPIは、もともと3Dレンダリングを念頭に置いて設計されています。旧バージョンのパイプラインは、3Dジオメトリックデータの処理を中心に、頂点の変換やライティングなどのステージで構成された、完全に固定機能のパイプラインでした。この硬直性は、プログラム可能なパイプラインの柔軟性に取って代わられていますが、3Dジオメトリの処理に焦点を当てたものが今でも主流です。シーン内のオブジェクトの視覚的表現は、通常、アセット作成プロセスの一部として分離して構築され、シミュレーションにデータとしてインポートされます（図9.7）。シミュレーションされた多くのオブジェクト（単一のタイプのエンティティ）は、同じ視覚的表現を参照しますが、レンダリング時に位置や向きなどの個別の属性を適用します。メッシュは全体メッシュのローカル空間からの相対的な頂点位置として記述され、可視エンティティはエンティティのローカル原点からの相対的なメッシュのグループとして記述され、そのエンティティは包含空間からの相対的な記述が可能であり、すべての空間は最終的には単一のルート原点からの相対的なものとなります。このシステムは、多くのエンティティがシーン内の異なる位置で同じメッシュリソースを共有することを可能にするという大きな利点を持っています。レンダリングには、これらのワールドスペースの頂点をフレームバッファの2Dイメージ空間に入れるというステップが含まれています（図9.8）。これを行うには、シーン内の視点と投影されるシーンの可視ボリュームを表す空間を定義する必要があります。これらの追加変換は、camera または view frustum エンティティ内にカプセル化されます。同様に、出力情報は、どのフレームバッファに、必要に応じてそのフレームバッファのどのサブセクションにシーンがレンダリングされるかを指定する必要があります。この情報は、カメラオブジェクトに追加されたり、更なるオブジェクトに具現化されたりします。最も重要なことは、個々のエンティティ内に格納されている、または個々のエンティティによって参照される表現情報と、イメージとしてのシーンを合成する責任のある出力情報との間の鍵となる不一致を示していることです。
シーン内の透明なジオメトリのレンダリングなど、場合によっては、エンティティがレンダリングされる順番にさらに制約があります（図9.9）。これは、既存のシーンにそのようなエンティティを合成する際に線形補間を使用するためです。最終画像の正しい合成を達成するためには、2 つの追加基準を満たさなければなりません。透明なエンティティは、シーンの不透明な部分の後にレンダリングされなければならず、カメラから最も遠い透明なエンティティが最初にレンダリングされ、最も近いエンティティが最後にレンダリングされるように順序付けられなければなりません。リアルタイムの反射をレンダリングするなど、メインビューポイントからのシーンのレンダリングが、他のビューポイントからのシーンの前のレンダリングからの出力に依存する場合があります。これにより、レンダリングのためのパイプライン全体がインスタンス化されたシーンが作成されます。例えば、ライトの視点からシャドウマップをレンダリングする場合、深度情報のみを出力する必要があります。また、完全な色と光の画像を生成するために必要なシェーダやテクスチャなどのリソースを利用するのは非常に非効率的である。そのため、複数の表現が必要となるが、これはシーンの内容に基づいて動的に発生する可能性があり、後のパイプラインのインスタンスは先の結果に依存している（図 9.10）。
場合によっては、主視点と同一の出力が得られないことがあります。たとえば、ライトの視点からシャドウマップをレンダリングすると、深度情報だけが出力されます。また、完全な色と光の画像を生成するために必要なシェーダやテクスチャなどのリソースを利用するのは非常に非効率的である。そのため、複数の表現の候補を任意のエンティティで参照し、必要な出力に基づいて選択する必要がある（図 9.11）。

+ 後処理。前のセクションでは、3D空間から2Dフレームバッファに幾何学的形状を投影することに焦点を当てました。後処理の段階では、代わりに画像空間での操作が主に行われます。しかし、グラフィックスハードウェアは、特定のブレンディング操作を除いて、単一のフレームバッファからの読み取りと書き込みの両方を行うことができません。これは、後処理システムが前のフレームバッファの結果をテクスチャとしてアクセスし、変更された情報を新しいフレームバッファに書き込むという使用パターンを必要とします（図9.12）。後処理の各段階では、通常、フレームバッファへの単一バッチのレンダリングが必要となります。このバッチは、おそらくシミュレーション内のオブジェクトを表すものではなく、単に、ソース画像のすべてのピクセルが処理されてフレームバッファに出力されるようにするための画面整列四角形で構成されます。より複雑な後処理では、目的の効果を生み出すために多くの段階を必要とする場合があります。これは、1つまたは複数の前のフレームバッファの出力を使用して、それぞれが依存するバッチの連鎖になります。検査の上で、それはその後、後処理のために必要な機能は、以下に似ていないと言うことができます。
3Dシーンで説明されているように、反射やシャドウマップの作成に必要な
レンダリング部。実際、ヒートヘイズなどのエフェクトに関しては、いくつかの
レンダリングの2つの領域が重なっています。

+ GUIレンダリング。3Dシーンレンダリングとは対照的に、GUIシステムは一般的に3Dエンティティの投影には興味がなく、画面をカプセル化したより狭い空間で動作します。この空間には、インターフェイスの単一の要素を表す可能性のある様々なオブジェクトが配置されています。テキストやステータスバーのようなアクティブな要素から、ボタンのようなインタラクティブな要素まで、様々な要素があり、物理的なシミュレーションではないにしても論理的な要素を表すものや、静的な装飾的な要素などがあります。例えば、テキスト要素は装飾的なスプライトの前に表示されることがあります。この順序は、空間に奥行きを持たせたり、要素の位置を調整したりすることで表現できます（図9.13）。実際には、GUIをトランスペアレンシーを含む他の3Dシーンと同じように構築し、GUI要素をノーマレンティティとして扱い、そのようなシーンのためにすでに実装されている構造を有効に活用することがより効果的かもしれません。このアプローチは、ステレオグラフィック3Dでレンダリングする際にうまく機能するインターフェースを構築することの難しさに対処するという利点もあります。

+ まとめ。要約すると、エンティティ、シーン、スペース、カメラの定義を広げることで、3Dシーンをレンダリングするために必要な構造を、後処理やGUIレンダリングでも利用できるように拡張することができると言えます。同様に、すべてのシーンは、オブジェクトのパイプラインを使用してレンダリングされなければなりません。
  + シェーダのコンテキスト情報（ビューや投影行列など）。
  + レンダリングされるボリュームに関する情報をカリングします。
  + エンティティの正しいレンダリング順序。
  + 使用されるレンダリング領域とフレームバッファに関する情報を出力します。

潜在的なレンダリングパターンの調査は、決して網羅的なものではありません。
そのため、どのようなソリューションであっても、その性質上、拡張可能であることが重要です。
追加のパターンを容易に統合することができます。

### 9.2.3 Renderer Model
グラフィックスAPIとレンダリングのためのエンジンレベルのインターフェースを検討し、両者の活動の典型的なパターンを記述するための簡略化されたモデルを構築しました。2つのモデルを組み合わせることで、レンダラーの望ましい動作を正確に記述することが可能になります。アプリケーションの実行中の様々なポイントで、レンダラーは特定の機能を実行する必要があります。

+ セッション。ゲームのすべての可視要素は、3D、2D、または後処理段階に関係なく、レンダリングのための単一のインターフェイスを提供するエンティティで表現されるべきです。各可視エンティティは、シェーダ、メッシュ、テクスチャ、およびバッチ状態の観点から視覚的表現を記述するその他の情報の形でリソースを参照する必要があります（図9.14）。

+ フレーム。各フレームの間に、レンダリングの複数のステージを作成するために、さまざまなターゲットを特定の順序でレンダリングする必要があります。各ステージでは、おそらく新しいフレームバッファやビューポートへの変更を可能にするため、あるいは不透明なエンティティから透明なエンティティへの移行など、現在のものの構成に制約があるため、前のステージが完了するためにレンダリングを行う必要があります。
+ ステージ。各ステージは、それが観察しているシーンからエンティティをフィルタリングするカメラオブジェクトから最初に構成されるパイプラインを形成し、独自の criteria.The result group of entities は、この特定のステージで指定された操作を使用してソートすることができます。正しく並べ替えられると、エンティティは、このステージに関連するすべての代表的なデータのために照会される（図 9.15）。

+ バッチ。エンティティからの代表的なデータは、単一バッチの基礎を形成するために使用されます。レンダリングステージの他の要素は、正しいビューポート寸法やフレームバッファなどのバッチの残りの状態を提供します。このバッチは次のバッチに移る前に実行できます（図9.16）。

### 9.2.4 Further Considerations

レンダラーの基本的な操作を定義した後、開発中に考慮すべき追加の要件が多数あります。API は同じ一般的なモデルを採用していますが、一部の有用な機能は特定の API に固有のものであり、ハードウェアの進歩に応じて新しい機能が利用できるようになります。これらの機能を公開するためにレンダラーを迅速に拡張できるようにすることが重要です。複数のレンダリング技術のサポート 特定のビジュアル プロパティを持つエンティティは、異なるレンダリング スタイル（フォワード/デファード シェーディングなど）を持つ複数のプロジェクトに存在する場合もあれば、異なるハードウェア機能を持つ複数のプラットフォームにまたがる同じプロジェクトに存在する場合もあります。1 つのビジュアルエフェクトの異なる実装の間で、できれば 1 つのデータセットから選択できることが重要です。新しいグラフィックス技術は常に開発されており、レンダリングの新しいパターンは、コードやデータ形式への影響を最小限に抑えてレンダラーに簡単に統合できることが重要です。

レンダラーの基本操作を定義した後、開発中に考慮すべき追加要件が多数あります。

+ 多様な API 機能の公開。API は同じ一般的なモデルを採用していますが、一部の有用な機能は特定の API に固有のものであり、ハードウェアの進歩に応じて新しい機能が利用できるようになります。これらを公開するためにレンダラーを迅速に拡張できるようにすることが重要です。

+ 複数のレンダリング技術をサポートします。複数のレンダリング技術のサポート 特定のビジュアル プロパティを持つエンティティは、異なるレンダリング スタイル（フォワード/ディファード シェーディングなど）を持つ複数のプロジェクトに存在する場合もあれば、異なるハードウェア機能を持つ複数のプラットフォームにまたがる同じプロジェクトに存在する場合もあります。1 つのビジュアル エフェクトの異なるインプリメンテーション間で、できれば 1 つのデータ セットから選択できることが重要です。

+ 拡張可能なアーキテクチャ。新しいグラフィックス技術は常に開発されており、レンダリングの新しいパターンは、コードやデータ形式への影響を最小限に抑えてレンダラーに簡単に統合できることが重要です。

+ レンダラリソース管理。デバイスのリソースは有限であり、どのようなソリューションでも、可能な限りリソースの重複を最小限に抑えることを試みなければなりません。しかし、包括的なリソース管理スキームは、この章の範囲を超えています。

## 9.3 Solution Development
レンダラの正確な設計を説明する前に、実装の一般的なアプローチを決定することをお勧めします。

### 9.3.1 Object-Based Pipeline

 レンダラの設計と追加の制約は、高度にモジュール化された実装に適しています。セクション 9.2.3 で導出されたモデルを検討すると、レンダラーの機能が独立した操作であり、単一のバッチを構築するために直列に実行されるパターンが現れていることがわかります。この設計パターンは、パイプラインまたはパイプとフィルターのパターンとして定義されることが多いです [Buschmann et al. このパターンは、エンジンにアセットをロードする前に開発者がアセットを処理するために使用する多くのアセット パイプラインや、「API」セクションで説明したグラフィックス パイプラインにも見られます。ある意味では、レンダラー パイプラインは、これら 2 つのパイプラインの延長線上にあると考えることができ、アセットとデバイスの状態の間のギャップを埋めることができます。このようなきめ細かなモジュール性により、データとしてのパイプラインの構成と、コードとしてのコンポーネントの機能を切り離すことができ、多くの利点があります。

+ アクセシビリティ。少し説明するだけで、アーティストやその他のアセット クリエイターは、プログラマーの介入なしにレンダラーを構成するために使用されるデータセットを理解し、変更することができるはずです。このプロセスは、ユーザーが視覚的なインターフェイスを介してレンダラー設定をオーサリングできるツールを提供することで、さらに向上させることができます。

+ 柔軟性。柔軟性。エンジンの実行中でも、作成元のデータセットを変更することで、レンダラーの構造を迅速に変更できるようにする必要があります。これにより、プロジェクトのワークフローに影響を与えることなく、さまざまな構成をすばやくテストでき、また、セッションによって要件が変化する可能性があるため、レンダリングを最適化する機会を得ることができます。

+ 拡張性。拡張性：オブジェクトは、同じインターフェイスにマッチしながらも新しい動作をもたらす新しいオブジェクトタイプを追加することでアーキテクチャを拡張することができ、新しいレンダリングパターンや新しいAPI機能の公開に関して将来的な検証が可能になります。


### 9.3.2 Device Object

Direct3D ライブラリのように明示的にも暗黙的にも、すべてのグラフィックス API には中央のデバイスオブジェクトがあることはすでに指摘されています。レンダラコードの移植性を実証するためには、基礎となる API に関係なく、単一のインターフェイスを使用するようにコンポーネントを記述することが理にかなっています。同様に、APIにデバイスオブジェクトの概念がすでに存在していても、このインターフェイスではデバイスオブジェクトの概念を形式化することが理にかなっています。ある機能が与えられたAPIでサポートされていない場合は、エミュレートする必要があるか、レンダラーがデータを通して構成されているため、現在のデータセットが完全にサポートされていないことを警告することができます。新しい機能が利用可能になると、それらを公開するために追加のレンダラー コンポーネントを記述する前にデバイス インターフェイスを拡張する必要があります。

### 9.3.3 Deriving State from Objects

前述のように、各バッチをレンダリングする際に、レンダラーはエンティティとパイプラインを形成するオブジェク トのリストを反復処理して、そのバッチをレンダリングするのに必要な状態の各割合を導出します。グラフィックスパイプラインに見られるさまざまなタイプのステート（9.2.1項）と、シミュレーション内のエンティティを表すオブジェク トとパイプラインを表すオブジェクト（9.2.3項）を区別することが重要です。イテレーションにより、オブジェクトは状態設定のためにデバイスにアクセスすることが保証されます。

+ 固定関数ステート。固定機能状態を含むオブジェクトは、管理が容易である。イテレーションがパイプラインまたはエンティティ内のそのようなノードに到達すると、そのノードはデバイスにアクセスして正しい呼び出しを行うことができるようになります。

+ シェーダパラメータ。シェーダパラメータの値を正しく設定するのは、非常に難しい課題です。各パラメータは、タイプと名前、オプションのセマンティック（セマンティックがシェーディング言語でサポートされている場合）で識別されますが、名前とセマンティック値の間にはある程度の冗長性があります。実際には、名前は意味論の短縮版であることが多いです（例えば、world-view matrixmightは意味論のWORLDVIEWを持っていますが、省略名のWVmを持っています）。名前は、任意のparam-eterの要件であり、したがって、すべてのシェーダコードで利用可能であることが保証されていますが、命名規則を保証することはできませんし、プロジェクト全体にわたって実施する必要があります。アプリケーション間のセマンティクスの使用を標準化することで、この問題を解決しようとするSAS（Standard Annotations and Semantics）というイニシアチブがあります。

パラメータを正しく設定するには、プログラムのロジック内で同等の変数を見つける必要があります。残念ながら、コンパイルでは通常、変数からコンテキストが削除されるため、各オブジェクトのメンバ変数の型と名前による検索を単純に行うことができません(図9.17)。2つの解決策が考えられます。

+ そのような変数を提供する任意のオブジェクトに検索関数を組み込んで、パラメータに最もよくマッチするメンバ変数へのポインタを返します（見つからない場合はNULLポインタ）[Cafrelli 01]。このアプローチは、エンティティ型の継承階層を使用する既存のエンジンに最も適しているかもしれません。このアプローチには、コード内で固定の名前付けや意味語彙を強制するという欠点があります。
+ クラスの代わりにデータ集約を使用して実体型を定義します。各オブジェクトは、型と名前または意味に基づいて実際に検索できるノードの構造としてその変数を格納することができます。これは多くのエンジンアーキテクチャでは現実的ではないかもしれませんが、柔軟性という利点があり、新しい9.4.Representational Objectsdataをエンティティに挿入したり、割り当てられたシェーダによって自動的にピックアップされたりすることができます。

データを検索するコストがかかるため、シェーダパラメータと変数の間のこれらのリンクは、フレームごとではなく、エンティティとシェーダを初期化する際にセッションごとに一度形成する必要があります。これらのリンクは、エンティティを表すデータを含むものと、レンダリング時の現在のコンテキストやパイプラインの構成を含むものの2つに分けることができます。

+ 表現オブジェクト。すべての可視オブジェクトは、シーン内の単一のユニークなエンティティによって表現されますが、そのエンティティは、他の任意の数のエンティティによって共有されている可能性のあるリソースオブジェクトを参照することができます。これらのオブジェクトは、様々な異なる条件の下で、エンティティを1つ以上のバッチとして表現するために必要な情報を提供します。この情報は、フレームの期間にわたって静止したままの値に限定される（世界空間におけるエンティティの絶対位置など）。また、レンダリングの正確な瞬間にエンティティがどのように表示されるかを決定するためには、それ以上の情報が必要です（使用中の特定のカメラの位置など）。可能性のあるバッチごとに、エンティティはすべてのシェーダパラメータと、それらを設定するために使用された変数間のリンクを格納します。関連するデータがエンティティ内または参照されているリソースのいずれかで利用可能な場合、これを使用します。

+ コンテキスト/パイプラインオブジェクト。データがエンティティで直接利用できない場合は、グローバル コンテキスト エンティティから参照することができます。このエンティティは一意で、アッシャーダ内からパイプラインの現在の状態を記述するために必要なすべての変数を含んでいます。フレームの途中でパイプラインが変化すると、そのコンポーネントはコンテキストエンティティに格納されている変数を変更し、レンダリングされたバッチが正しい入力を得ることを保証します。

## 9.4 Representational Objects

このように、単一のエンティティの視覚的な表現は、複数の オブジェクトを参照します。各オブジェクトはより一般的なリソースを参照し、追加のレイヤーを追加します。 のユニークなインスタンスへと進行します。 エンティティを使用しています。効果的には、これにより、リソースがより具体的になる階層が作成されます。 根元に近づくにつれて、その根元にある資源が減少していきます（図9.18）。 これらの資源の正確な性質はやや恣意的であり、構造 使用されているエンジンは，エンジン間で容易に異なる可能性がある．彼らの選択の基準は、グループ化することです。 の状態を、バッチ間で変化する頻度で大まかに表現します。 は異なるパラメータで複数回使用される可能性があります。 周波数が低いほど 物体の特異性が高くなると、周波数も高くなります。 で変更されます。 階層の各階層がより具体的になっているため、提供された値はすべて それによって、より一般的なリソースからのものよりも優先されます。

### 9.4.1 Effect
エフェクトの概念は、グラフィックスやAPI プログラミングの深い知識を必要としない方法で、プロ グラム可能なグラフィックスパイプラインの側面にアクセス可能にします。これは、これらの要素をパイプライン内での目的ではなく、最終的な結果である独自の視覚的品質に基づいた構造にカプセル化することによって行われます（図9.19）。本章では、コンポーネント名の意味、エフェクトが機能であるAPIで提供されているドキュメント、およびこのテーマに関する既存のソース[St-Laurent 05]に基づいて解釈します。
+ テクニック。エフェクト内の各技術は、比較可能な結果を達成するための異なる方法です。個々のテクニックにアノテーションを適用することで、必要な機能や相対的なコストなどのさまざまな基準でそれらをグループ化することができ、レンダラーは状況に応じて適切なテクニックをアルゴリズム的に選択することができます。
+ パス。1 つのバッチで効果を達成できるとは限らず、フレーム全体のさまざまなポイントでレンダリングする複数の連続したバッチが必要になる場合があります。各テクニックは 1 つまたは複数のパスから構成されています。これらのパスには、レンダラーがフレーム内の適切なポイントで実行するように指示するための注釈を付けることができます。パスには、シェーダやステート割り当てなど、同様の変更頻度を持つステートが含まれていますが、これらはパイプライン全体の構成を作成するために相互に依存しているため、個別に利用することはほとんどありません。そのため、このテクニックの各パスは、シェーダとステートアサインを組み合わせたものですが、シェーダのパラメータ値の多くを取り込み、効果的にグラフィックパイプラインのインターフェースを作成して、エフェクト全体をパラメータ化することができます。
+ デフォルト値。エフェクトがすべてのパラメータにデフォルト値を提供することで、新しいテクニックを実装するのに必要な時間が短縮されます。それは、より特定のリソースによってオーバーライドされる必要のある値の数を、厳密に必要なものだけに最小化します。

### 9.4.2 Assets

アセットは、パラメータの一部に入力を提供することで、特定のエフェクトをさらに特化します。これらは通常、少なくとも一部はエンジンの外部ツールを使用してオーサリングされます。3D アセットの作成では、マテリアルとメッシュという用語が一般的に使用されますが、これらは GUI やポストプロセスのレンダリングにも同様に適用できます。

+ マテリアル。一般的に、マテリアルは、特定の物質の品質をエミュレートするために効果を特殊化する定数とテクスチャ情報で構成されています。さらに、この概念を後処理にまで拡張すると、静的な値を持つエフェクトのau-thored構成またはチューニングと考えることができます。

+ メッシュ。メッシュは、すべての頂点データストリームとインデックスのセットであり、エフェクトのためのすべての変化する入力をカプセル化します。アセット作成ツールで提供されるように、この情報が直接使用されない場合が多くあります。その代わりに、エンジン内のシステムアイテムは、グラフィックスデバイスに転送する前に、頂点ストリームを生成または修正します。これには、メッシュのアニメーション、パーティクルエフェクト、GUIテキスト用のメッシュの生成などが含まれます。

より完全なリソース管理システムは、効率を向上させるためにこれらのリソースのインスタンス化をサポートする可能性が高いでしょう。しかし、この章ではそのような詳細については触れません。

### 9.4.3 Simulation
アセットセクションのリソースが主にバッチの視覚的属性に関係していたのに対し、このセクションでは論理属性.Entityクラスを表すオブジェクトに関係しています。ゲームデザインプロセスの一部として、アーキタイプのエンティティは、多くの個々のエンティティーが共有する視覚的属性と論理的属性の観点からデスクリプションされます。これらの属性は、個々のエンティティ間で変化せず、ゲーム・セッションの間でも変化しないため、安全に共有することができる。個々のエンティティは特定のクラスのインスタンスであり、実際のシミュレートされたオブジェクトを表します。そのため、各インスタンスを一意にするすべての値が含まれており、ゲームセッションの間や個々のインスタンス間で変化する値が含まれています。

## 9.5 Pipeline Objects
パイプラインは、 交換可能な一連のオブジ ェ ク ト で構成 さ れてお り 、 各オブジ ェ ク ト は同じ イ ン タ ーフ ェ イ ス を持ち ます。このパイプラインは、フレームの 1 つの段階でエンティティのグループのレンダリングを制御します（図 9.20）。

### 9.5.1 Contextual Objects
+ コンテキストオブジェクトは、代表的なものと同様の方法でエフェクトに値を提供します。コンテキストオブジェクトは、代表オブジェクトと同様にエフェクトに値を提供しますが、間接的なレベルがあります。エフェクトパラメータは、グローバルコンテキストオブジェクト内で定義された値にリンクされており、これらの値は、バッチがレンダリングされている現在のコンテキストを反映するようにフレームの間で操作されます。

+ カメラ。Camera.Camera.Cameraオブジェクトも、おそらく目に見えるものではないでしょうが、シーン内のエンティティになる可能性が高いでしょう。カメラは、現在の空間からフレームバッファの空間にエンティティを投影するために使用される変換を担当します。カメラは、ワールドスペース内での位置など、エフェクトで使用するための他の情報を提供することもあります。正確な詳細はシステムの実装者の裁量に委ねられている。

+ ビューポート。ビューポートは、フレームバッファの長方形の領域を定義し、その中でレンダリングを行い、出力画像はフィットするようにクロップされるのではなく、スケーリングされます。ビューポートは、絶対値だけでなく相対値を使用して動作するように拡張することができ、パイプラインをオーサリングする際に特定のターゲットの解像度を知る必要性を切り離します。これをさらに拡張して、ビューポートの入れ子を可能にし、それぞれの子は直系の親の相対値から寸法を導き出すことができます。

+ ターゲット。レンダー ターゲットは、使用するフレームバッファの内容を定義し、プラットフォームが提供するクライアント エリアまたはレンダリングの次の段階で使用する可能性のあるテクスチャのいずれかを参照します。


### 9.5.2 Control Objects

対照的に、コントロール オブジェクトはエフェクト パラメータの状態を設定しません。その代わりに、レンダリングされるバッチの順序と選択を制御します。

+ カメラ。カメラオブジェクトは、レンダリング中にコンテクストデータを提供するだけでなく、表現データを取得する前にエンティティのカリングを行うことができます。

+ レイヤー。レイヤー（Layer）は、シングルレンダーターゲット全体のレンダリングをコース単位で制御するために使用することができます。これにより、1つのバッチのセットは、前のセットが完了した後にのみレンダリングされます。その名が示すように、 それらは Photoshop や GIMP のようなアートパッケージのレイヤーに類似しています。

+ ソートアルゴリズム。ソートアルゴリズム パイプラインのソートアルゴリズムを定義すると、レンダリングが実行される前に任意の基準でエンティティを強制的にソートすることができます。これは、 半透明のバッチを1 つのレイヤーのレンダリングに合成するための要件ですが、これを利用して、素材やおおよその画面カバレージに基づいてバッチを並べ替えることによってパフォーマンスを向上させることもできます。

+ エフェクトから正しいテクニックを選択するための追加情報を提供するために、テクニックフィルタを適用することができます。各フィルタは、プラットフォーム、必要な機能、またはレンダリングスタイルなど、1つ以上のドメインで値を提供することができます。各ドメインは、フレーム内のどの時点でも 1 つの値しか持つことができず、これらの値は、利用可能なエフェクト テクニックによって指定されたドメイン値と一致し、最適なものを選択することができます（図 9.21）。テクニックフィルターは、大規模なプロジェクトや大規模なエフェクトライブラリを使用している場合に最も有用であり、大部分はオプションです。
パスフィルタ（Pass Filter）。パス フィルタ（Pass Filter）：パス フィルタは、テクニック フィルタとは異なり、各フィルタには識別値があり、フレーム内の 1 つのポイントで任意の数のパス フィルタをアクティブにすることができます。エンティティをレンダリングする際には、現在のテクニック内でアクティブなフィルタに一致するすべてのパスがレンダリングされます。使用されているソート・アルゴリズムに関係なく、テクニックで事前に指定された順序が観察されます(図9.22)。アクティブなフィルタに一致するパスがない場合は、何も表示されません。

### 9.6 Frame Graph
パイプラインの構成は、各フレームの途中でステージごとに異なります。代表的なリソースと同様に、パイプラインの構成要素は異なる頻度で変化する。したがって、フレーム全体の過程でパイプラインを様々な構成要素のグラフとして記述することが可能である（図 9.23）。

このグラフは、現在のレンダリング段階に基づいてフレームを効果的に分割し、ノードをアクティブなパイプラインコンポーネントとしています。グラフをルートからリーフへと反復して処理することで、フレームの各ステージのパイプラインを形成します。各リーフ ノードは、レンダリングが必要な完全なパイプライン コンフィグレーションを表しています。グラフの深さを最初にトラバースすることで、各パイプライン構成を順番に反復し、フレーム全体をレンダリングすることが可能になります。グラフの各ノードが反復されると、それがアクティブになり、コンテキストオブジェクトまたはパイプラインの制御状態を変更します。リーフノードに到達すると、カメラオブジェクトはそのステージのレンダリングを開始し、シーングラフの反復処理を行い、パイプラインの状態に基づいて可視エンティティを処理します。パイプラインの概念は有効ですが、グローバルな状態を変更するこの動作は、システムの実装をよりスタックに似たものにしています。これにより、特定の状態の変更の頻度が大幅に減少し、レンダリング中のパイプライン全体を各バッチで反復処理するよりも大幅に効率的になります。

### 9.7 Case Study: Praetorian Tech

PraetorianはCohort Studio独自のエンジン技術です。Praetorianは、複数のプラットフォームでフルタイトルやプロトタイプを構築するための強固なプラットフォームを提供するために開発されました（図9.24）。

### 9.7.1 Motivation

Praetorianは、複数の同時プロジェクト間でコードの再利用を最大化することを意図して開発されました。これを念頭に置いて、エンジンコードではなく、データとスクリプトで各プロジェクトに固有の機能を定義し、アーティスト、デザイナー、ゲームプレイプログラマーがプロジェクトのルック＆フィールを詳細にコントロールできるようにしたのは理にかなっています（図9.25）。前述したように、エフェクトファイルは、データを介してプログラマブルなグラフィックスを公開するための自然な解決策となりました。広範囲のアートパッケージとの互換性があるため、多くのアーティストがすでにエフェクトファイルの使用に精通しており、場合によってはオーサリングにも精通していました。しかし、より高度なビジュアルエフェクトでは、エフェクトファイルだけでは定義できない、フレームの途中で複数回のパスが必要になることがわかりました。フレームをマップアウトして参照点を与え、様々なレベルの粒度でレンダリングの順序をコントロールできるAdata構造が必要でした。

### 9.7.2 Implementation Details

Praetorianの設計は、本章の序章で説明したコンセプトに基づいています。その核となるのは、エンジンのサブシステムによって提供されるオブジェクトの機能性を、中央のシーングラフに格納された生データから分割した、非常に柔軟性の高いアーキテクチャです。そのため、シーン内のすべてのエンティティは、データオブジェクトのリストを格納した単一のクラスによってコードで表現され、区別されています。メッシュとマテリアルへの参照を含むエンティティは描画され、物理オブジェクトを持つエンティティは物理シミュレーションによって更新されます。このように、キャラクターやライトのような単一の概念的なエンティティは、シーン内の単一のエンティティとして表現されたり、単一のルートノードの下にグループ化されたエンティティのサブグラフとして表現されたりすることができます。このような詳細は、コードによって導かれたというよりも、アーティストやデザイナーによって制作されたアセットによって主に知らされていました。

このアプローチにより、この章で議論されているレンダラーのコンセプトの多くをエム・ボディ化できるサブグラフをシーンに追加することが簡単になりました。この章で説明するデザインは、結果として得られたアーキテクチャの改良版です。

### 9.7.3 Analysis

レンダラー設計の目的は、グラフィックス開発とエンジンの開発を分離し、エフェクトファイルによってすでに提供されているものを超えて、データを通してグラフィックスAPIの機能を公開することでした。これにより、メインプロジェクトのフォワードシェーディングから繰延シェーディングに移行し、繰延ライティングや推論ライティング、さまざまな形式のセルシェーディング、その他の非フォトリアリスティックレンダリング方法など、さまざまなスタイルやバリエーションを試してみたところ、非常に成功したことがわかりました。デザインが成功したもう1つの領域は、ポスト処理技術の定義にあります。これらの技術は、他のエフェクトと同じ開発環境の恩恵を受けているだけでなく、同じプロジェクトで複数のレベルにまたがって完全に設定可能であることからも恩恵を受けています。ある程度までは、レンダラーのデータ駆動型の性質は、その初期および継続的な開発では制限となりました。いくつかの単純なタスクの場合、データを使って機能を公開するエレガントな方法を設計し実装するのには、コードを使って機能を公開するよりもかなり時間がかかりました。しかし、そのような構造が整っていれば、時間の節約で初期投資をすぐに補うことができます。Praetorianの初期構造は、この章で説明したものよりもかなり硬いものでした。このため、シャドウ・フラスタム計算やステレオカメラなどの特殊なケースの動作を追加することは、実装がより困難になりました。これは、システムの利便性を低下させ、エラーが発生する可能性を高めるという望ましくない効果をもたらしました。解決策の 1 つは、ファイルを解釈するためのビジュアル エディタを作成することであったでしょう。レンダリングされるバッチについて最小限の仮定を行うことで、効率を最大化することが困難になる場合があります。最大の効果は、ロード中やアセットパイプラインの一部として可能な限り多くの処理を実行し、ワークロードをレンダリング時から遠ざけることでした。これはシステムのランタイムの柔軟性に影響を与え、データが追加されたり削除されたりした場合にはエンティティの再初期化を余儀なくされますが、全体的には現実的なフレームレートを維持する必要がありました。


## 9.8 Further Work and Considerations

###  9.8.1 Optimization: Multithreaded Rendering Using
一部のAPIでは、別々のスレッドで複数のコマンドバッファを作成することをサポートしています。各スレッドは、リーフノードに到達するまで繰り返し処理を行います。各スレッドは、リーフノードに到達するまで反復処理を行い、結果として得られたパイプラインを正常に処理する前にノードをロックします。このアプローチを同時実行エラーから安全にするために、各スレッドはメインデバイスの機能のサブセットを持つローカルデバイスを持つことになります。このアプローチを同時実行エラーから安全にするために、各スレッドはメインデバイスの機能のサブセットを持つローカルデバイスを持つことになり、現在のパイプラインの状態を保存するためにスレッドローカルのコンテキストエンティティが必要になります。


### 9.8.2 Extension: Complex Contextual Data 
シェーダーによっては、次のような単一のエンティティ内に存在しないデータを必要とするものもあります。
を連結した世界観投影行列を作成します。このデータは
シェーダを構成パーツから作成しますが、パフォーマンスコストはかなり高くなります。
バッチごとに一度だけ生成するよりも このように、システムを追加することで、オペレーショ
コンテキスト エンティティの値とレンダリングされるエンティティの値を組み合わせて表示します。
レンダリングの前に 最も高度な状態では、これは
バッチシェーダの一種である拡張エフェクトファイルに埋め込まれた実行可能なスクリプト。

### 9.8.3 Debugging: Real-Time Toggling of Elements in Pipeline
デバッグ情報を表示するためのシェーダは
の効果に追加のテクニックを追加することができます。これらのテクニックは以下のようにして発動させることができます。
フレームグラフに正しいフィルタを追加することで、これらのセクションを切り替えて、さまざまな条件でさまざまなエンティティをレンダリングし、情報を表示します。
レンダラは、法線、オーバードロー、または照明などの機能を使用しています。レンダラーは自動的にシェーダパラメータをエンティティデータに変換することで、さまざまな情報を視覚化することが可能になります。
シェーダコードのみを変更することで、デバッグを行うことができます。このデバッグ情報は厳密にはデータによって制御されているため、導入や削除が簡単で
個々の開発者は、特定のニーズに合わせて出力を調整してから
出荷前にすべての参照先を確認してください。

## 9.9 Conclusion

この章で説明するレンダラーは、グラフグラフィックスレンダリングの詳細をエンジンアーキテクチャから切り離すことに成功しています。このようにして、現在販売されているものよりも、グラフィックプログラマーやアセットクリエイターのニーズに合ったインターフェイスを提供しようとしています。将来的には、これらのコンセプトを発展させて、表示するアプリケーションを問わず、グラフィックスの技術全体を記述するための標準化された表記法を作成することも可能になるかもしれません。

### 9.10 Acknowledgments

私の最初の仕事がこのような素晴らしい経験になったのは、長年にわたってコホートスタジオで働いてくれた皆さんのおかげです。私はその時間の中で多くのことを学びました。未来があなたを見つけるところはどこでも、すべてのベストを尽くします。Praetorianにも最初から携わってくれたAndrew Collinson氏、2人の卒業生プログラマーにエンジンの設計と構築を任せることに大きな信頼を示してくれたBruce McNeish氏、アーティストはプログラマーの支援なしでレンダーターゲットを定義できるようにすべきだと要求してくれたAlex Perkins氏に特別な感謝の意を表したいと思います。


## Bibliography
[Bell 10] G. Bell. “How to Build Your Own Engine and Why You Should.” Develop 107
(July 2010), 54–55.
[Buschmann et al. 96] F. Buschmann, R. Meunier, H. Rohnert, P. Sommerland, and M.
Stal. Pattern-Oriented Software Architecture. Chichester, West Sussex, UK: John
Wiley & Sons, 1996.
[Cafrelli 01] C. Cafrelli. “A Property Class for Generic C++ Member Access.” In Game
Programming Gems 2, edited by Mark DeLoura, pp. 46–50. Hingham, MA: Charles
River Media, 2001.
[Microsoft 09] Microsoft Corporation. “DirectX SDK.” Available at http://msdn.
microsoft.com/en-us/directx/default.aspx, 2009.
[Shodhan and Willmott 10] S. Shodhan and A. Willmott. “Stylized Rendering in
Spore.” In GPU Pro, edited by Wolfgang Engel, pp. 549–560. Natick, MA: A K
Peters, 2010.
[Shreiner et al. 06] D. Shreiner, M. Woo, J. Neider, and T. Davis. OpenGL Program-
ming Guide, Fifth edition. Upper Saddle River, NJ: Addison Wesley, 2006.
[St-Laurent 05] S. St-Laurent. The COMPLETE Effect and HLSL Guide. Redmond,
WA: Paradoxal Press, 2005.
[Sterna 10] W. Sterna. “Porting Code between Direct3D9 and OpenGL 2.0.” In GPU
Pro, edited by Wolfgang Engel, pp. 529–540. Natick, MA: A K Peters, 2010.
